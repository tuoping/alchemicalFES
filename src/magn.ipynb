{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "seq_dim=(6,6)\n",
    "\n",
    "magn = np.arange(-np.prod(seq_dim), np.prod(seq_dim)+1, 2)\n",
    "bins=np.linspace(magn[0]-1, magn[-1]+1, np.prod(seq_dim)+1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "def loadmodelprediction(_dirname, epoch=None, num_batches=1, file_header=\"logits\"):\n",
    "    dirname = _dirname\n",
    "    f_logits_t = glob.glob(os.path.join(dirname, file_header+\"_val_inttime*\"))\n",
    "    print(\">>> Reading model predictions from: \", dirname)\n",
    "\n",
    "    logits_t = np.array([np.load(f).astype(np.float16) for f in f_logits_t])\n",
    "    diffusion_t = np.array([float(x.replace(os.path.join(dirname, file_header+\"_val_inttime\"), \"\").replace(\".npy\",\"\"))-1 for x in f_logits_t])\n",
    "    idx_order = np.argsort(diffusion_t)\n",
    "    logits_t = logits_t[idx_order]\n",
    "    diffusion_t = diffusion_t[idx_order]\n",
    "    return logits_t, diffusion_t\n",
    "\n",
    "def logits2seq(logits_t):\n",
    "    seq_t = []\n",
    "    for logits in logits_t:\n",
    "        seq = np.argmax(logits, axis=-1)\n",
    "        seq[np.where(seq==0)] = -1\n",
    "        seq_t.append(seq.reshape(-1,*seq_dim))\n",
    "    return seq_t\n",
    "\n",
    "def Ising_magnetization(seq):\n",
    "    data = np.sum(seq.reshape([-1,np.prod(seq_dim)]), axis=-1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculateError(free_energys_list_, num_samples=4):\n",
    "    free_energys_list_ = np.array(free_energys_list_)\n",
    "    std_free = np.std(free_energys_list_, axis=0)\n",
    "    standard_error = std_free / np.sqrt(num_samples)\n",
    "    t_critical = 1.96\n",
    "    margin_of_error = t_critical * standard_error\n",
    "    free_energies = np.mean(free_energys_list_, axis=0)\n",
    "    return free_energies, margin_of_error\n",
    "\n",
    "from functools import reduce\n",
    "def histvar(seq, varfunc, bins, num_samples):\n",
    "    var = varfunc(seq)\n",
    "    if var.shape[0]<1024*4:\n",
    "        print(\"WARNING:: sample not enough to generate reliable error bars\")\n",
    "    P_all = []\n",
    "    idxF_all = []\n",
    "    hist_all = []\n",
    "    bin_centers_all = []\n",
    "    for ii in range(num_samples):\n",
    "        hist, bin_edges = np.histogram(var[ii::num_samples], bins=bins)\n",
    "        bin_centers = np.array([(bin_edges[i]+bin_edges[i+1])/2. for i in range(len(bin_edges)-1)])\n",
    "        bin_centers_all.append(bin_centers)\n",
    "        hist_all.append(hist)\n",
    "        P = hist/np.sum(hist)\n",
    "        P_all.append(P)\n",
    "        idxF = np.where(hist>0)\n",
    "        idxF_all.append(idxF)\n",
    "        # F = -np.log(P[idxF])\n",
    "        # F_all.append(F)\n",
    "    P_all = np.array(P_all)\n",
    "    hist_all = np.array(hist_all)\n",
    "    idxF_res = reduce(np.intersect1d, tuple(idxF_all))\n",
    "    if num_samples == 1:\n",
    "        idxF_res = idxF_res[0]\n",
    "    F_all = []\n",
    "    for ii in range(num_samples):\n",
    "        F = -np.log(P_all[ii][idxF_res])\n",
    "        F_all.append(F)\n",
    "    F_all = np.array(F_all)\n",
    "\n",
    "    for ii in range(num_samples-1):\n",
    "        if not np.array_equal(bin_centers_all[ii], bin_centers_all[ii+1]):\n",
    "            raise Exception(\"ERROR:: bin_centers not consistant\")\n",
    "    hist = np.mean(hist_all)\n",
    "    P_res = calculateError(P_all)\n",
    "    F_res = calculateError(F_all)\n",
    "    return hist, bin_centers_all[0], P_res, F_res, np.array(idxF_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_t, diffusion_t = loadmodelprediction(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([logits.shape for logits in logits_t])\n",
    "print(max(diffusion_t))\n",
    "print(diffusion_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_t = logits2seq(logits_t)\n",
    "magn_samples_t = [Ising_magnetization(seq) for seq in seq_t]\n",
    "print([magn.shape for magn in magn_samples_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReadReferenceF(filename):\n",
    "    ofile_prob_E = open(filename,\"r\")\n",
    "    Reference_dict = {}\n",
    "    idx_jj = 0\n",
    "    while(True):\n",
    "        line = ofile_prob_E.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        bin_centers = np.array([float(x) for x in line.split()])\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        jj = float(line.split()[-1].replace(\"kBT=\",\"\"))\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        F = np.array([float(x) for x in line.split()])\n",
    "\n",
    "        Reference_dict[jj]=np.stack([bin_centers, F])\n",
    "    ofile_prob_E.close()\n",
    "    return Reference_dict\n",
    "\n",
    "ref_dirname = \"/nfs/scistore23/chenggrp/ptuo/NeuralRG/data/ising-latt%dx%d-T4.0/latt%dx%d/\"%(*seq_dim, *seq_dim)\n",
    "Reference_dict = ReadReferenceF(os.path.join(ref_dirname, \"F-MAGN-REF.dat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Reference_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_color = [plt.colormaps[\"jet_r\"](float(i)/float(len(diffusion_t))) for i in range(len(diffusion_t))]\n",
    "line_color = [plt.colormaps[\"gnuplot\"](float(i)/3.) for i in range(3)]\n",
    "line_marker = [\"o\", \"x\", \"o\"]\n",
    "line_s = [10]\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "for idx_t, i in enumerate([len(diffusion_t)-1]):\n",
    "    hist_E, bin_centers_E, P_E, F_E, idxF_E = histvar(seq_t[i], Ising_magnetization, bins, num_samples=1)\n",
    "\n",
    "    sigma_gkernel = 1\n",
    "    y_smoothed = gaussian_filter1d(F_E[0], sigma_gkernel)\n",
    "    errors_smoothed = gaussian_filter1d(F_E[1], sigma_gkernel)\n",
    "\n",
    "    plt.scatter(bin_centers_E[idxF_E], F_E[0], label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], marker=line_marker[idx_t], s=line_s[idx_t])\n",
    "    # plt.errorbar(bin_centers_E[idxF_E], F_E[0], yerr=F_E[1], label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], fmt=\"o\", alpha=0.5, capsize=2)\n",
    "    # plt.errorbar(bin_centers_E[idxF_E], y_smoothed, yerr=errors_smoothed, label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], fmt=\"-\")\n",
    "    # plt.fill_between(bin_centers_E[idxF_E], F_E[0]-F_E[1], y2=F_E[0]+F_E[1], label=\"Time=%.2f\"%(diffusion_t[i]), color=line_color[idx_t], alpha=0.8, edgecolor=line_color[idx_t])\n",
    "    print(F_E[1].mean(), F_E[1].max(), F_E[1].min())\n",
    "T = 1.2\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T)\n",
    "T = 3.2\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T, linestyle=\"--\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Magnetization\")\n",
    "plt.ylabel(\"Negative likelihood\")\n",
    "# plt.xlim((magn.min(), magn.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _logits_t, _ = loadmodelprediction(\"../epoch159_IntStep80_AMax10_clsT2.4L6shuffle0.6_scoreG1.0_bs9216\")\n",
    "# logits_t = [np.concatenate([logits_t[i], _logits_t[i]], axis=0) for i in range(len(_logits_t))]\n",
    "# seq_t = logits2seq(logits_t)\n",
    "# print([logits.shape for logits in logits_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_color = [plt.colormaps[\"jet_r\"](float(i)/float(len(diffusion_t))) for i in range(len(diffusion_t))]\n",
    "line_color = [plt.colormaps[\"gnuplot\"](float(i)/3.) for i in range(3)]\n",
    "line_marker = [\"o\", \"x\", \"o\"]\n",
    "line_s = [1, 100, 10]\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "for idx_t, i in enumerate([len(diffusion_t)-1]):\n",
    "    hist_E, bin_centers_E, P_E, F_E, idxF_E = histvar(seq_t[i], Ising_magnetization, bins, num_samples=4)\n",
    "\n",
    "    sigma_gkernel = 1\n",
    "    y_smoothed = gaussian_filter1d(F_E[0], sigma_gkernel)\n",
    "    errors_smoothed = gaussian_filter1d(F_E[1], sigma_gkernel)\n",
    "\n",
    "    plt.scatter(bin_centers_E[idxF_E], F_E[0], label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], marker=line_marker[idx_t], s=line_s[idx_t])\n",
    "    # plt.errorbar(bin_centers_E[idxF_E], F_E[0], yerr=F_E[1], label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], fmt=\"o\", alpha=0.5, capsize=2)\n",
    "    # plt.errorbar(bin_centers_E[idxF_E], y_smoothed, yerr=errors_smoothed, label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], fmt=\"-\")\n",
    "    # plt.fill_between(bin_centers_E[idxF_E], F_E[0]-F_E[1], y2=F_E[0]+F_E[1], label=\"Time=%.2f\"%(diffusion_t[i]), color=line_color[idx_t], alpha=0.8, edgecolor=line_color[idx_t])\n",
    "    print(F_E[1].mean(), F_E[1].max(), F_E[1].min())\n",
    "T = 1.0\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T)\n",
    "T = 3.2\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T, linestyle=\"--\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Magnetization\")\n",
    "plt.ylabel(\"Negative likelihood\")\n",
    "plt.title(\"Evalucation batch size = %d\"%seq_t[0].shape[0])\n",
    "# plt.xlim((magn.min(), magn.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofile_fes = open(\"FES-MAGN.dat\", \"wb\")\n",
    "for idx_t, i in enumerate(range(len(diffusion_t))):\n",
    "    # if diffusion_t[i] >= 1.0:\n",
    "    #     break\n",
    "    hist_E, bin_centers_E, P_E, F_E, idxF_E = histvar(seq_t[i], Ising_magnetization, bins, num_samples=4)\n",
    "    np.savetxt(ofile_fes, bin_centers_E[idxF_E].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; Magnetization\")\n",
    "    np.savetxt(ofile_fes, F_E[0].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; FES\")\n",
    "    np.savetxt(ofile_fes, F_E[1].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; ERROR of FES\")\n",
    "ofile_fes.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class IsingGNN(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(IsingGNN, self).__init__()\n",
    "        self.L = L  # Lattice size\n",
    "        self.edge_index = self.generate_lattice_edges(L)\n",
    "    \n",
    "    def generate_lattice_edges(self, L):\n",
    "        edges = []\n",
    "        for i in range(L):\n",
    "            for j in range(L):\n",
    "                # current node index\n",
    "                node = i * L + j\n",
    "                \n",
    "                # Add edges to the right and down (to avoid double counting)\n",
    "                right = i * L + (j + 1) % L\n",
    "                down = ((i + 1) % L) * L + j\n",
    "                left = i * L + (j - 1) % L\n",
    "                up = ((i - 1) % L) * L + j\n",
    "                \n",
    "                edges.append([node, right])\n",
    "                edges.append([node, down])\n",
    "                edges.append([node, left])\n",
    "                edges.append([node, up])\n",
    "        \n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        return edge_index\n",
    "\n",
    "    def forward_hard(self, x):\n",
    "        B, seq_len, K = x.shape\n",
    "        assert seq_len == self.L**2\n",
    "        edge_index = self.edge_index.to(x.device)\n",
    "        # Get the spin values for the edge pairs\n",
    "        spin_values = torch.argmax(x, dim=-1) * 2 - 1  # Convert one-hot encoding to -1, 1\n",
    "        total_energy = torch.zeros(B).to(x.device)\n",
    "        for edge in range(edge_index.size(1)):\n",
    "            source = edge_index[0, edge]\n",
    "            target = edge_index[1, edge]\n",
    "            total_energy += -spin_values[:,source] * spin_values[:,target]/2.\n",
    "        return total_energy\n",
    "\n",
    "    def forward_soft(self, x):\n",
    "        B, seq_len, K = x.shape\n",
    "        assert seq_len == self.L**2\n",
    "        edge_index = self.edge_index.to(x.device)\n",
    "        # Get the spin values for the edge pairs\n",
    "        spin_values = torch.argmax(x, dim=-1) * 2 - 1  # Convert one-hot encoding to -1, 1\n",
    "        total_energy = torch.zeros(B).to(x.device)\n",
    "        for i in range(seq_len):\n",
    "            # Calculate energy assuming the current spin is -1\n",
    "            spin_values_neg1 = spin_values.clone()\n",
    "            spin_values_neg1[:,i] = -1\n",
    "            energy_neg1 = torch.zeros(B).to(x.device)\n",
    "            for edge in range(edge_index.size(1)):\n",
    "                source = edge_index[0, edge]\n",
    "                target = edge_index[1, edge]\n",
    "                energy_neg1 += -spin_values_neg1[:,source] * spin_values_neg1[:,target]/2.\n",
    "\n",
    "            # Calculate energy assuming the current spin is 1\n",
    "            spin_values_pos1 = spin_values_neg1\n",
    "            spin_values_pos1[:,i] = 1\n",
    "            energy_pos1 = torch.zeros(B).to(x.device)\n",
    "            for edge in range(edge_index.size(1)):\n",
    "                source = edge_index[0, edge]\n",
    "                target = edge_index[1, edge]\n",
    "                energy_pos1 += -spin_values_pos1[:,source] * spin_values_pos1[:,target]/2.\n",
    "            del spin_values_pos1\n",
    "            # Combine the energies weighted by the probabilities\n",
    "            spin_energy = x[:, i, 0] * energy_neg1 + x[:, i, 1] * energy_pos1\n",
    "            total_energy += spin_energy\n",
    "        return total_energy/seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ising_model = IsingGNN(seq_dim[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
