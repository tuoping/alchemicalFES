{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "seq_dim=(6,6)\n",
    "\n",
    "magn = np.arange(-np.prod(seq_dim), np.prod(seq_dim)+1, 2)\n",
    "bins=np.linspace(magn[0]-1, magn[-1]+1, np.prod(seq_dim)+1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "def loadmodelprediction(_dirname, epoch=None, num_batches=1, file_header=\"logits\"):\n",
    "    dirname = _dirname\n",
    "    f_logits_t = glob.glob(os.path.join(dirname, file_header+\"_val_inttime*\"))\n",
    "    print(\">>> Reading model predictions from: \", dirname)\n",
    "\n",
    "    logits_t = np.array([np.load(f).astype(np.float16) for f in f_logits_t])\n",
    "    diffusion_t = np.array([float(x.replace(os.path.join(dirname, file_header+\"_val_inttime\"), \"\").replace(\".npy\",\"\"))-1 for x in f_logits_t])\n",
    "    idx_order = np.argsort(diffusion_t)\n",
    "    logits_t = logits_t[idx_order]\n",
    "    diffusion_t = diffusion_t[idx_order]\n",
    "\n",
    "    for ii in range(num_batches):\n",
    "        if ii == 0:\n",
    "            print(\"        \", len(logits_t), [logits_t[i].shape for i in range(len(logits_t))])\n",
    "            continue\n",
    "        dirname = _dirname+\"../epoch%d_sampleIntStep80_%d\"%(epoch,ii+1)\n",
    "        _f_logits_t = sorted(glob.glob(os.path.join(dirname, file_header+\"_val_inttime*\")))\n",
    "        _logits_t = np.array([np.load(f).astype(np.float16) for f in _f_logits_t])[idx_order]\n",
    "        print(\"        \", ii+1,len(_logits_t), [_logits_t[i].shape for i in range(len(_f_logits_t))])\n",
    "        logits_t = [np.concatenate([logits_t[i], _logits_t[i]], axis=0) for i in range(len(_f_logits_t))]\n",
    "    return logits_t, diffusion_t\n",
    "\n",
    "def logits2seq(logits_t):\n",
    "    seq_t = []\n",
    "    for logits in logits_t:\n",
    "        seq = np.argmax(logits, axis=-1)\n",
    "        seq[np.where(seq==0)] = -1\n",
    "        seq_t.append(seq.reshape(-1,*seq_dim))\n",
    "    return seq_t\n",
    "\n",
    "def Ising_magnetization(seq):\n",
    "    data = np.sum(seq.reshape([-1,np.prod(seq_dim)]), axis=-1)\n",
    "    return data\n",
    "\n",
    "def histvar(seq, varfunc, bins):\n",
    "    var = varfunc(seq)\n",
    "    hist, bin_edges = np.histogram(var, bins=bins)\n",
    "    bin_centers = np.array([(bin_edges[i]+bin_edges[i+1])/2. for i in range(len(bin_edges)-1)])\n",
    "    P = hist/np.sum(hist)\n",
    "    idxF = np.where(hist>0)\n",
    "    F = -np.log(P[idxF])\n",
    "    return hist, bin_centers, P, F, idxF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_t, diffusion_t = loadmodelprediction(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([logits.shape for logits in logits_t])\n",
    "print(max(diffusion_t))\n",
    "print(diffusion_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_t = logits2seq(logits_t)\n",
    "magn_samples_t = [Ising_magnetization(seq) for seq in seq_t]\n",
    "print([magn.shape for magn in magn_samples_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReadReferenceF(filename):\n",
    "    ofile_prob_E = open(filename,\"r\")\n",
    "    Reference_dict = {}\n",
    "    idx_jj = 0\n",
    "    while(True):\n",
    "        line = ofile_prob_E.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        bin_centers = np.array([float(x) for x in line.split()])\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        jj = float(line.split()[-1].replace(\"kBT=\",\"\"))\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        F = np.array([float(x) for x in line.split()])\n",
    "\n",
    "        Reference_dict[jj]=np.stack([bin_centers, F])\n",
    "    ofile_prob_E.close()\n",
    "    return Reference_dict\n",
    "\n",
    "ref_dirname = \"/nfs/scistore14/chenggrp/ptuo/NeuralRG/data/ising-latt%dx%d-T4.0/latt%dx%d/\"%(*seq_dim, *seq_dim)\n",
    "Reference_dict = ReadReferenceF(os.path.join(ref_dirname, \"F-MAGN-REF.dat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_color = [plt.colormaps[\"jet_r\"](float(i)/float(len(diffusion_t))) for i in range(len(diffusion_t))]\n",
    "line_color = [plt.colormaps[\"gnuplot\"](float(i)/3.) for i in range(3)]\n",
    "line_marker = [\"o\", \"x\", \"o\"]\n",
    "line_s = [1, 100, 10]\n",
    "# for i in range(0, len(diffusion_t), 10):\n",
    "for idx_t, i in enumerate([0, len(diffusion_t)-2, len(diffusion_t)-1]):\n",
    "    # if diffusion_t[i] >= 1.0:\n",
    "    #     break\n",
    "    hist_E, bin_centers_E, P_E, F_E, idxF_E = histvar(seq_t[i], Ising_magnetization, bins)\n",
    "    plt.scatter(bin_centers_E[idxF_E], F_E, label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], marker=line_marker[idx_t], s=line_s[idx_t])\n",
    "T = 3.2\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Magnetization\")\n",
    "plt.ylabel(\"Negative likelihood\")\n",
    "# plt.xlim((magn.min(), magn.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class IsingGNN(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(IsingGNN, self).__init__()\n",
    "        self.L = L  # Lattice size\n",
    "        self.edge_index = self.generate_lattice_edges(L)\n",
    "    \n",
    "    def generate_lattice_edges(self, L):\n",
    "        edges = []\n",
    "        for i in range(L):\n",
    "            for j in range(L):\n",
    "                # current node index\n",
    "                node = i * L + j\n",
    "                \n",
    "                # Add edges to the right and down (to avoid double counting)\n",
    "                right = i * L + (j + 1) % L\n",
    "                down = ((i + 1) % L) * L + j\n",
    "                left = i * L + (j - 1) % L\n",
    "                up = ((i - 1) % L) * L + j\n",
    "                \n",
    "                edges.append([node, right])\n",
    "                edges.append([node, down])\n",
    "                edges.append([node, left])\n",
    "                edges.append([node, up])\n",
    "        \n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        return edge_index\n",
    "\n",
    "    def forward_hard(self, x):\n",
    "        B, seq_len, K = x.shape\n",
    "        assert seq_len == self.L**2\n",
    "        edge_index = self.edge_index.to(x.device)\n",
    "        # Get the spin values for the edge pairs\n",
    "        spin_values = torch.argmax(x, dim=-1) * 2 - 1  # Convert one-hot encoding to -1, 1\n",
    "        total_energy = torch.zeros(B).to(x.device)\n",
    "        for edge in range(edge_index.size(1)):\n",
    "            source = edge_index[0, edge]\n",
    "            target = edge_index[1, edge]\n",
    "            total_energy += -spin_values[:,source] * spin_values[:,target]/2.\n",
    "        return total_energy\n",
    "\n",
    "    def forward_soft(self, x):\n",
    "        B, seq_len, K = x.shape\n",
    "        assert seq_len == self.L**2\n",
    "        edge_index = self.edge_index.to(x.device)\n",
    "        # Get the spin values for the edge pairs\n",
    "        spin_values = torch.argmax(x, dim=-1) * 2 - 1  # Convert one-hot encoding to -1, 1\n",
    "        total_energy = torch.zeros(B).to(x.device)\n",
    "        for i in range(seq_len):\n",
    "            # Calculate energy assuming the current spin is -1\n",
    "            spin_values_neg1 = spin_values.clone()\n",
    "            spin_values_neg1[:,i] = -1\n",
    "            energy_neg1 = torch.zeros(B).to(x.device)\n",
    "            for edge in range(edge_index.size(1)):\n",
    "                source = edge_index[0, edge]\n",
    "                target = edge_index[1, edge]\n",
    "                energy_neg1 += -spin_values_neg1[:,source] * spin_values_neg1[:,target]/2.\n",
    "\n",
    "            # Calculate energy assuming the current spin is 1\n",
    "            spin_values_pos1 = spin_values_neg1\n",
    "            spin_values_pos1[:,i] = 1\n",
    "            energy_pos1 = torch.zeros(B).to(x.device)\n",
    "            for edge in range(edge_index.size(1)):\n",
    "                source = edge_index[0, edge]\n",
    "                target = edge_index[1, edge]\n",
    "                energy_pos1 += -spin_values_pos1[:,source] * spin_values_pos1[:,target]/2.\n",
    "            del spin_values_pos1\n",
    "            # Combine the energies weighted by the probabilities\n",
    "            spin_energy = x[:, i, 0] * energy_neg1 + x[:, i, 1] * energy_pos1\n",
    "            total_energy += spin_energy\n",
    "        return total_energy/seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ising_model = IsingGNN(seq_dim[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
