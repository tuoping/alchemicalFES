{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "seq_dim=(6,6)\n",
    "\n",
    "min_E = -np.prod(seq_dim)*2.\n",
    "max_E = np.prod(seq_dim)*2.*3./4.\n",
    "num_bins = int((max_E-min_E)/2)\n",
    "bins = np.linspace(min_E-1./num_bins, max_E+1./num_bins, num_bins+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "def loadmodelprediction(_dirname, epoch=None, num_batches=1, file_header=\"logits\"):\n",
    "    dirname = _dirname\n",
    "    f_logits_t = glob.glob(os.path.join(dirname, file_header+\"_val_inttime*\"))\n",
    "    print(\">>> Reading model predictions from: \", dirname)\n",
    "\n",
    "    logits_t = np.array([np.load(f).astype(np.float16) for f in f_logits_t])\n",
    "    diffusion_t = np.array([float(x.replace(os.path.join(dirname, file_header+\"_val_inttime\"), \"\").replace(\".npy\",\"\"))-1 for x in f_logits_t])\n",
    "    idx_order = np.argsort(diffusion_t)\n",
    "    logits_t = logits_t[idx_order]\n",
    "    diffusion_t = diffusion_t[idx_order]\n",
    "    return logits_t, diffusion_t\n",
    "\n",
    "def logits2seq(logits_t):\n",
    "    seq_t = []\n",
    "    for logits in logits_t:\n",
    "        seq = np.argmax(logits, axis=-1)\n",
    "        seq[np.where(seq==0)] = -1\n",
    "        seq_t.append(seq.reshape(-1,*seq_dim))\n",
    "    return seq_t\n",
    "\n",
    "def Ising_magnetization(seq):\n",
    "    data = np.sum(seq.reshape([-1,np.prod(seq_dim)]), axis=-1)\n",
    "    return data\n",
    "\n",
    "def pbc(i,L=seq_dim[0]):\n",
    "    assert i>=-1 and i<=L\n",
    "    if i-L == 0:\n",
    "        return 0\n",
    "    elif i == -1:\n",
    "        return L-1\n",
    "    else:\n",
    "        return i\n",
    "    \n",
    "from copy import deepcopy\n",
    "def ising_boltzman_prob_nn(seq, J=1, kBT=1.0):\n",
    "    shape = seq.shape\n",
    "    # spins = seq.clone().detach()\n",
    "    spins = deepcopy(seq)\n",
    "    spins[np.where(spins==0)]=-1\n",
    "    B,H,W = shape\n",
    "    E = np.zeros(B)\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            E += -spins[:,i,j]*spins[:,pbc(i-1),j]*J\n",
    "            E += -spins[:,i,j]*spins[:,pbc(i+1),j]*J\n",
    "            E += -spins[:,i,j]*spins[:,i,pbc(j-1)]*J\n",
    "            E += -spins[:,i,j]*spins[:,i,pbc(j+1)]*J\n",
    "\n",
    "    E /= 2\n",
    "    # prob = np.exp(-E/kBT)\n",
    "    return E/kBT\n",
    "\n",
    "def calculateError(free_energys_list_, num_samples=4):\n",
    "    free_energys_list_ = np.array(free_energys_list_)\n",
    "    std_free = np.std(free_energys_list_, axis=0)\n",
    "    standard_error = std_free / np.sqrt(num_samples)\n",
    "    t_critical = 1.96\n",
    "    margin_of_error = t_critical * standard_error\n",
    "    free_energies = np.mean(free_energys_list_, axis=0)\n",
    "    return free_energies, margin_of_error\n",
    "\n",
    "from functools import reduce\n",
    "def histvar(seq, varfunc, bins, num_samples):\n",
    "    var = varfunc(seq)\n",
    "    if var.shape[0]<1024*4:\n",
    "        print(\"WARNING:: sample not enough to generate reliable error bars\")\n",
    "    P_all = []\n",
    "    idxF_all = []\n",
    "    hist_all = []\n",
    "    bin_centers_all = []\n",
    "    for ii in range(num_samples):\n",
    "        hist, bin_edges = np.histogram(var[ii::num_samples], bins=bins)\n",
    "        bin_centers = np.array([(bin_edges[i]+bin_edges[i+1])/2. for i in range(len(bin_edges)-1)])\n",
    "        bin_centers_all.append(bin_centers)\n",
    "        hist_all.append(hist)\n",
    "        P = hist/np.sum(hist)\n",
    "        P_all.append(P)\n",
    "        idxF = np.where(hist>0)\n",
    "        idxF_all.append(idxF)\n",
    "        # F = -np.log(P[idxF])\n",
    "        # F_all.append(F)\n",
    "\n",
    "    P_all = np.array(P_all)\n",
    "    hist_all = np.array(hist_all)\n",
    "    idxF_res = reduce(np.intersect1d, tuple(idxF_all))\n",
    "    if num_samples == 1:\n",
    "        idxF_res = idxF_res[0]\n",
    "    F_all = []\n",
    "    for ii in range(num_samples):\n",
    "        F = -np.log(P_all[ii][idxF_res])\n",
    "        F_all.append(F)\n",
    "    F_all = np.array(F_all)\n",
    "\n",
    "    for ii in range(num_samples-1):\n",
    "        if not np.array_equal(bin_centers_all[ii], bin_centers_all[ii+1]):\n",
    "            raise Exception(\"ERROR:: bin_centers not consistant\")\n",
    "    hist = np.mean(hist_all)\n",
    "    P_res = calculateError(P_all, num_samples=num_samples)\n",
    "    F_res = calculateError(F_all, num_samples=num_samples)\n",
    "    return hist, bin_centers_all[0], P_res, F_res, np.array(idxF_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_t, diffusion_t = loadmodelprediction(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([logits.shape for logits in logits_t])\n",
    "print(max(diffusion_t))\n",
    "print(diffusion_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_t = logits2seq(logits_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReadReferenceF(filename, readerror=False):\n",
    "    ofile_prob_E = open(filename,\"r\")\n",
    "    Reference_dict = {}\n",
    "    idx_jj = 0\n",
    "    while(True):\n",
    "        line = ofile_prob_E.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        bin_centers = np.array([float(x) for x in line.split()])\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        jj = float(line.split()[-1].replace(\"kBT=\",\"\"))\n",
    "\n",
    "        line = ofile_prob_E.readline()\n",
    "        F = np.array([float(x) for x in line.split()])\n",
    "        if readerror:\n",
    "            line = ofile_prob_E.readline()\n",
    "            if not \"ERROR\" in line: \n",
    "                raise Exception(\"ERROR:: ERROR data not found in \", filename)\n",
    "            line = ofile_prob_E.readline()\n",
    "            errF = np.array([float(x) for x in line.split()])\n",
    "        if readerror:\n",
    "            Reference_dict[jj]=np.stack([bin_centers, F, errF])\n",
    "        else:\n",
    "            Reference_dict[jj]=np.stack([bin_centers, F])\n",
    "    ofile_prob_E.close()\n",
    "    return Reference_dict\n",
    "\n",
    "ref_dirname = \"/nfs/scistore23/chenggrp/ptuo/NeuralRG/data/ising-latt%dx%d-T4.0/latt%dx%d/\"%(*seq_dim, *seq_dim)\n",
    "Reference_dict = ReadReferenceF(os.path.join(ref_dirname, \"F-E-REF.dat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Reference_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_color = [plt.colormaps[\"gnuplot\"](float(i)/float(len(diffusion_t))) for i in range(len(diffusion_t))]\n",
    "# line_color = [plt.colormaps[\"gnuplot\"](float(i)/3.) for i in range(3)]\n",
    "# line_marker = [\"o\", \"x\", \"o\"]\n",
    "# line_s = [1, 100, 10]\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "for idx_t in [len(diffusion_t)-1]:\n",
    "    hist_E, bin_centers_E, P_E, F_E, idxF_E = histvar(seq_t[idx_t], ising_boltzman_prob_nn, bins, num_samples=1)\n",
    "    sigma_gkernel = 3\n",
    "    y_smoothed = gaussian_filter1d(F_E[0], sigma_gkernel)\n",
    "    errors_smoothed = gaussian_filter1d(F_E[1], sigma_gkernel)\n",
    "\n",
    "    # plt.plot(bin_centers_E[idxF_E], F_E[0], label=\"Time=%.2f\"%(diffusion_t[idx_t]), c=line_color[idx_t], s=3)\n",
    "    plt.errorbar(bin_centers_E[idxF_E], F_E[0], yerr=F_E[1], label=\"Time=%.2f\"%(diffusion_t[idx_t]), c=line_color[idx_t], fmt=\"o\")\n",
    "    # plt.errorbar(bin_centers_E[idxF_E], y_smoothed, yerr=errors_smoothed, label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], fmt=\"-\")\n",
    "    # plt.fill_between(bin_centers_E[idxF_E], F_E[0]-F_E[1], y2=F_E[0]+F_E[1], label=\"Time=%.2f\"%(diffusion_t[i]), color=line_color[idx_t], alpha=0.8, edgecolor=line_color[idx_t])\n",
    "\n",
    "T = 2.4\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T)\n",
    "T = 2.8\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T, linestyle=\"--\")\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Potential energy (J)\")\n",
    "plt.ylabel(\"Negative likelihood\")\n",
    "plt.title(\"Evalucation batch size = %d\"%seq_t[0].shape[0])\n",
    "# plt.xlim((magn.min(), magn.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_color = [plt.colormaps[\"gnuplot\"](float(i)/float(len(diffusion_t))) for i in range(len(diffusion_t))]\n",
    "# line_color = [plt.colormaps[\"gnuplot\"](float(i)/3.) for i in range(3)]\n",
    "# line_marker = [\"o\", \"x\", \"o\"]\n",
    "# line_s = [1, 100, 10]\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "for idx_t in [len(diffusion_t)-1]:\n",
    "    hist_E, bin_centers_E, P_E, F_E, idxF_E = histvar(seq_t[idx_t], ising_boltzman_prob_nn, bins, num_samples=4)\n",
    "    sigma_gkernel = 3\n",
    "    y_smoothed = gaussian_filter1d(F_E[0], sigma_gkernel)\n",
    "    errors_smoothed = gaussian_filter1d(F_E[1], sigma_gkernel)\n",
    "\n",
    "    # plt.plot(bin_centers_E[idxF_E], F_E[0], label=\"Time=%.2f\"%(diffusion_t[idx_t]), c=line_color[idx_t], s=3)\n",
    "    plt.errorbar(bin_centers_E[idxF_E], F_E[0], yerr=F_E[1], label=\"Time=%.2f\"%(diffusion_t[idx_t]), c=line_color[idx_t], fmt=\"o\")\n",
    "    # plt.errorbar(bin_centers_E[idxF_E], y_smoothed, yerr=errors_smoothed, label=\"Time=%.2f\"%(diffusion_t[i]), c=line_color[idx_t], fmt=\"-\")\n",
    "    # plt.fill_between(bin_centers_E[idxF_E], F_E[0]-F_E[1], y2=F_E[0]+F_E[1], label=\"Time=%.2f\"%(diffusion_t[i]), color=line_color[idx_t], alpha=0.8, edgecolor=line_color[idx_t])\n",
    "print(F_E[1].mean())\n",
    "\n",
    "T = 1\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T)\n",
    "T = 3.2\n",
    "if T in Reference_dict:\n",
    "    plt.plot(Reference_dict[T][0], Reference_dict[T][1], c=\"green\", label=\"Ground truth ($k_BT=%.1f$)\"%T, linestyle=\"--\")\n",
    "    \n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Potential energy (J)\")\n",
    "plt.ylabel(\"Negative likelihood\")\n",
    "plt.title(\"Evalucation batch size = %d\"%seq_t[0].shape[0])\n",
    "# plt.xlim((magn.min(), magn.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _logits_t, _ = loadmodelprediction(\"../epoch159_IntStep80_AMax10_clsT2.4L6shuffle0.6_scoreG1.0_bs9216\")\n",
    "# logits_t = [np.concatenate([logits_t[i], _logits_t[i]], axis=0) for i in range(len(_logits_t))]\n",
    "# print([logits.shape for logits in logits_t])\n",
    "# seq_t = logits2seq(logits_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "magn = Ising_magnetization(seq_t[-1])\n",
    "pote = ising_boltzman_prob_nn(seq_t[-1])\n",
    "\n",
    "H, xedges, yedges, img = plt.hist2d(magn, pote, bins=100, cmap=\"Blues\", density=True, vmax=0.0004)\n",
    "X, Y = np.meshgrid(xedges[:-1], yedges[:-1])\n",
    "plt.colorbar()\n",
    "# plt.scatter(magn_c4[ridx], pote_c4[ridx], marker=\"*\", c=\"red\", s=60)\n",
    "# plt.ylim((-300, -25))\n",
    "plt.subplot(122)\n",
    "# _ = plt.imshow(seq_c4[ridx], cmap='Greys', vmin=0, vmax=1)\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "plt.contour(X, Y, H.T, levels=10, cmap=\"plasma\")\n",
    "plt.colorbar()\n",
    "# plt.ylim((-300, -25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "ofile_fes = open(\"FES-E.dat\", \"wb\")\n",
    "# ofile_fes_smooth = open(\"FES-E-smoothed.dat\", \"wb\")\n",
    "ofile_prob = open(\"PROB-E.dat\", \"wb\")\n",
    "for idx_t, i in enumerate(range(len(diffusion_t))):\n",
    "\n",
    "    hist_E, bin_centers_E, P_E, F_E, idxF_E = histvar(seq_t[i], ising_boltzman_prob_nn, bins, num_samples=4)\n",
    "    np.savetxt(ofile_fes, bin_centers_E[idxF_E].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; Potential energy (J)\")\n",
    "    np.savetxt(ofile_fes, F_E[0].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; FES\")\n",
    "    np.savetxt(ofile_fes, F_E[1].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; ERROR of FES\")\n",
    "\n",
    "    # sigma_gkernel = 3\n",
    "    # y_smoothed = gaussian_filter1d(F_E[0], sigma_gkernel)\n",
    "    # errors_smoothed = gaussian_filter1d(F_E[1], sigma_gkernel)\n",
    "    # np.savetxt(ofile_fes_smooth, bin_centers_E[idxF_E].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; Potential energy (J)\")\n",
    "    # np.savetxt(ofile_fes_smooth, y_smoothed.reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; FES\")\n",
    "    # np.savetxt(ofile_fes_smooth, errors_smoothed.reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; ERROR of FES\")\n",
    "\n",
    "    np.savetxt(ofile_prob, bin_centers_E.reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; Potential energy (J)\")\n",
    "    np.savetxt(ofile_prob, P_E[0].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; PROB\")\n",
    "    np.savetxt(ofile_prob, P_E[1].reshape(1,-1), delimiter=\" \", header=f\"alpha-1={diffusion_t[i]}; ERROR of PROB\")\n",
    "\n",
    "\n",
    "ofile_fes.close()\n",
    "ofile_prob.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class IsingGNN(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(IsingGNN, self).__init__()\n",
    "        self.L = L  # Lattice size\n",
    "        self.edge_index = self.generate_lattice_edges(L)\n",
    "    \n",
    "    def generate_lattice_edges(self, L):\n",
    "        edges = []\n",
    "        for i in range(L):\n",
    "            for j in range(L):\n",
    "                # current node index\n",
    "                node = i * L + j\n",
    "                \n",
    "                # Add edges to the right and down (to avoid double counting)\n",
    "                right = i * L + (j + 1) % L\n",
    "                down = ((i + 1) % L) * L + j\n",
    "                left = i * L + (j - 1) % L\n",
    "                \n",
    "                edges.append([node, right])\n",
    "                edges.append([node, down])\n",
    "                edges.append([node, left])\n",
    "                edges.append([node, up])\n",
    "        \n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        return edge_index\n",
    "\n",
    "    def forward_hard(self, x):\n",
    "        B, seq_len, K = x.shape\n",
    "        assert seq_len == self.L**2\n",
    "        edge_index = self.edge_index.to(x.device)\n",
    "        # Get the spin values for the edge pairs\n",
    "        spin_values = torch.argmax(x, dim=-1) * 2 - 1  # Convert one-hot encoding to -1, 1\n",
    "        total_energy = torch.zeros(B).to(x.device)\n",
    "        for edge in range(edge_index.size(1)):\n",
    "            source = edge_index[0, edge]\n",
    "            target = edge_index[1, edge]\n",
    "            total_energy += -spin_values[:,source] * spin_values[:,target]/2.\n",
    "        return total_energy\n",
    "\n",
    "    def forward_soft(self, x):\n",
    "        B, seq_len, K = x.shape\n",
    "        assert seq_len == self.L**2\n",
    "        edge_index = self.edge_index.to(x.device)\n",
    "        # Get the spin values for the edge pairs\n",
    "        spin_values = torch.argmax(x, dim=-1) * 2 - 1  # Convert one-hot encoding to -1, 1\n",
    "        total_energy = torch.zeros(B).to(x.device)\n",
    "        for i in range(seq_len):\n",
    "            # Calculate energy assuming the current spin is -1\n",
    "            spin_values_neg1 = spin_values.clone()\n",
    "            spin_values_neg1[:,i] = -1\n",
    "            energy_neg1 = torch.zeros(B).to(x.device)\n",
    "            for edge in range(edge_index.size(1)):\n",
    "                source = edge_index[0, edge]\n",
    "                target = edge_index[1, edge]\n",
    "                energy_neg1 += -spin_values_neg1[:,source] * spin_values_neg1[:,target]/2.\n",
    "\n",
    "            # Calculate energy assuming the current spin is 1\n",
    "            spin_values_pos1 = spin_values_neg1\n",
    "            spin_values_pos1[:,i] = 1\n",
    "            energy_pos1 = torch.zeros(B).to(x.device)\n",
    "            for edge in range(edge_index.size(1)):\n",
    "                source = edge_index[0, edge]\n",
    "                target = edge_index[1, edge]\n",
    "                energy_pos1 += -spin_values_pos1[:,source] * spin_values_pos1[:,target]/2.\n",
    "            del spin_values_pos1\n",
    "            # Combine the energies weighted by the probabilities\n",
    "            spin_energy = x[:, i, 0] * energy_neg1 + x[:, i, 1] * energy_pos1\n",
    "            total_energy += spin_energy\n",
    "        return total_energy/seq_len\n",
    "    \n",
    "ising_model = IsingGNN(seq_dim[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
